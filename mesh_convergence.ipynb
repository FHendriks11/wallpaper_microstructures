{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import helper_funcs as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = 'p4_square_2024-05-22_15-01-53.190117'\n",
    "# geom = 'p4m_square_2024-05-22_15-08-35.472754'\n",
    "# geom = 'p6_hexagonal_2024-05-22_15-52-16.388326'\n",
    "# geom = 'pg_rectangular_2024-05-22_14-21-22.169238'\n",
    "\n",
    "# specify path to folder for this geometry\n",
    "path = os.path.join(r'data', geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_file = os.path.join(path, geom + '_00.geo')\n",
    "print(geo_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original hmax = 0.1/sqrt(6) = 0.040824829046386304\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the directory where the mesh files will be saved\n",
    "save_dir = r'mesh_convergence_' + geom\n",
    "\n",
    "# create the directory if it does not exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .geo files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create .geo files with different hmax values\n",
    "hmax_arr = 2.0**np.arange(-8, -1.9, 0.5)\n",
    "for hmax in hmax_arr:\n",
    "    print(hmax)\n",
    "    # import the original .geo file:\n",
    "    with open(geo_file, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    # replace the hmax value:\n",
    "    for i, line in enumerate(data):\n",
    "        if line.startswith('Point('):\n",
    "            data[i] = line.rsplit(',', maxsplit=1)[0] + ', ' + str(hmax) + '};\\n'\n",
    "    data.extend([f'Mesh.CharacteristicLengthMax = {hmax};\\n',\n",
    "                 f'Mesh.CharacteristicLengthMin = {hmax};\\n'])\n",
    "    print(data)\n",
    "\n",
    "    # write the new .geo file:\n",
    "    with open(os.path.join(save_dir, f'hmax_{hmax}.geo'), 'w') as file:\n",
    "        file.writelines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create meshes and MatLab inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "import subprocess\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy\n",
    "import copy\n",
    "\n",
    "fig_nr = 0\n",
    "verbose = True\n",
    "figures = 0  # create lots of figuers\n",
    "\n",
    "group = geom.split('_')[0]\n",
    "print('Group:', group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_gmsh_mesh(file_path, element_type):\n",
    "    # Load the Gmsh mesh from the .msh file\n",
    "    mesh = meshio.read(file_path)\n",
    "\n",
    "    # Access mesh information\n",
    "    points = mesh.points[:, :2]\n",
    "    cells = mesh.cells\n",
    "    cell_data = mesh.cell_data\n",
    "\n",
    "    elements = np.array([], dtype=int).reshape(0, 6)\n",
    "    for cell in cells:\n",
    "        if cell.type == element_type:\n",
    "            elements = np.append(elements, cell.data, axis=0)\n",
    "\n",
    "    return points, cells, cell_data, elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed: .mat file with\n",
    "* p\n",
    "* t\n",
    "* lattice_vectors\n",
    "* boundary_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(save_dir)\n",
    "for file in files:  #['hmax_0.00390625.geo']:  #\n",
    "    try:\n",
    "        if not file.endswith('.geo'):\n",
    "            continue\n",
    "\n",
    "        start_time = time.time()\n",
    "        time_temp = time.time()\n",
    "        file_path = os.path.join(save_dir, file)\n",
    "        print(file_path)\n",
    "        print(file)\n",
    "        name = file[:-4]\n",
    "        print(name)\n",
    "\n",
    "        hmax = name.split('_')[1]\n",
    "        print('hmax:', hmax)\n",
    "\n",
    "    # %% [markdown]\n",
    "        # Run gmsh on created .geo file with\n",
    "        # Command example: 'gmsh', file, '-o', file2, '-2', '-clmax', str(hmax)]\n",
    "        # ['gmsh', 'test.geo', '-o', 'test.msh', '-2', '-clmax', '0.1']\n",
    "        # Explanation: gmsh: program to call, should be in path\n",
    "        # file: path to input file\n",
    "        # -o: specifying output file\n",
    "        # file2: path to output file\n",
    "        # -2: apparently indicates you want to use the command line interface of gmsh, without this it will open the gui\n",
    "        # -clmax: specifying max element size\n",
    "        # str(hmax): max element size\n",
    "\n",
    "        # create new file path with .msh instead of .geo\n",
    "        file2 = os.path.join(save_dir, f'{name}.msh')\n",
    "\n",
    "        if verbose:\n",
    "            print('Calling gmsh...')\n",
    "        command = f'gmsh \"{file_path}\" -o \"{file2}\" -2 -clmax {str(hmax)}'\n",
    "        print(f'command: {command}')\n",
    "        process = subprocess.call(command, shell=True)\n",
    "\n",
    "        if verbose:\n",
    "            print('succesfully ran gmsh')\n",
    "            print('Time for gmsh:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "            # print(process.stdout.read())\n",
    "\n",
    "        mesh = meshio.read(file2)\n",
    "        if verbose:\n",
    "            # print(mesh)\n",
    "            pass\n",
    "\n",
    "        # %%\n",
    "        # ## Import mesh\n",
    "\n",
    "\n",
    "\n",
    "        # %%\n",
    "        mesh_points, _, _, elements = import_gmsh_mesh(file2, 'triangle6')\n",
    "\n",
    "        # with open(hf.new_path(os.path.join(save_dir, f'{name}_fd.pkl')), 'wb') as f:\n",
    "        #     pickle.dump({'p': mesh_points, 't': elements}, f)\n",
    "\n",
    "        with open(os.path.join(path, f'{geom}_00.pkl'), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            uc = data['uc']\n",
    "            fd = data['fd']\n",
    "            unique_holes = data['unique_holes']\n",
    "\n",
    "        # %%\n",
    "        # Remove unused nodes\n",
    "        to_keep, inv = np.unique(elements, return_inverse=True)\n",
    "        mesh_points = mesh_points[to_keep]\n",
    "\n",
    "        # renumber elements\n",
    "        temp = np.full(elements.max()+1, -1, dtype=int)\n",
    "        temp[to_keep] = np.arange(len(to_keep))\n",
    "        elements = temp[elements]\n",
    "\n",
    "        # %%\n",
    "        # Check volume fraction again, this time of the actual mesh\n",
    "\n",
    "        temp = mesh_points[elements]\n",
    "        # temp = np.transpose(temp, axes=[0,2,1])\n",
    "        temp = temp[..., [0,3,1,4,2,5], :]\n",
    "        filled_area = np.sum(hf.polygon_area(temp))\n",
    "        total_area = 1.0/uc['n_fds']\n",
    "        vol_frac2 = filled_area/total_area\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Volume occupied = {vol_frac2*100:.1f}%')\n",
    "            print(f'Volume vacant = {(1-vol_frac2)*100:.1f}%')\n",
    "\n",
    "            print('Time for processing fundamental domain mesh:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% Turn fundamental domain into unit cell\n",
    "        all_mesh_points = []\n",
    "        all_elements = []\n",
    "        inds_per_fd = []\n",
    "        n = len(mesh_points)\n",
    "        for j, copy1 in enumerate(uc['transforms']):\n",
    "\n",
    "            p2 = np.copy(mesh_points)\n",
    "\n",
    "            for transform in copy1:\n",
    "\n",
    "                if transform[0] == 'T':\n",
    "                    p2 = hf.translate_points(p2, eval(transform[1]))\n",
    "                elif transform[0] == 'R':\n",
    "                    degrees = np.array(eval(transform[2]))\n",
    "                    p2 = hf.rotate_points(p2, eval(transform[1]), degrees/360*2*np.pi)\n",
    "                elif transform[0] == 'M':\n",
    "                    p2 = hf.mirror_points(p2, eval(transform[1]), eval(transform[2]))\n",
    "                else:\n",
    "                    raise NotImplementedError(f'transform {transform[0]} is not implemented')\n",
    "\n",
    "            all_mesh_points.append(np.copy(p2))\n",
    "            all_elements.append(np.copy(elements) + j*n)\n",
    "            inds_per_fd.append(np.arange(n) + j*n)\n",
    "\n",
    "        all_mesh_points = np.concatenate(all_mesh_points, axis=0)\n",
    "        all_elements = np.concatenate(all_elements, axis=0)\n",
    "        inds_per_fd = np.array(inds_per_fd)\n",
    "        if verbose:\n",
    "            print('all_mesh_points.shape', all_mesh_points.shape)\n",
    "            print('all_elements.shape', all_elements.shape)\n",
    "            print('inds_per_fd.shape', inds_per_fd.shape)\n",
    "\n",
    "        # %% Deduplicate points\n",
    "        start_time_dedup = time.time()\n",
    "        # deduplicate\n",
    "        all_mesh_points, inds, inv, c = hf.uniquetol(all_mesh_points, tol=1e-4, return_counts=True, return_index=True, return_inverse=True, axis=0)\n",
    "        if verbose:\n",
    "            print(f'Time for deduplication: {time.time() - start_time_dedup:.4} seconds')\n",
    "            print('Time for tiling into unit cell:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "        all_elements = inv[all_elements]\n",
    "        inds_per_fd = inv[inds_per_fd]\n",
    "\n",
    "        # %%\n",
    "        # Plot counts\n",
    "        if figures == 2:\n",
    "            fig = plt.figure(figsize=(10,10))\n",
    "            temp = all_mesh_points[all_elements]\n",
    "            temp = np.transpose(temp, axes=[0,2,1])\n",
    "            temp = temp[..., [0,3,1,4,2,5]]\n",
    "            temp = temp.reshape(-1, temp.shape[-1])\n",
    "            plt.fill(*temp, c='whitesmoke')\n",
    "            plt.title('counts per point, should be =/= 1 at and only at overlapping fundamental domain boundaries')\n",
    "\n",
    "            for count in np.unique(c):\n",
    "                plt.scatter(*all_mesh_points[c == count].T, s=count*5, zorder=10, label=count)\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.legend(title='count')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_counts.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        # %%\n",
    "        # Plot unit cell mesh\n",
    "        if figures in [1,2]:\n",
    "            fig = plt.figure(figsize=(10,10))\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            # background fundamental domain shape\n",
    "            plt.fill(*uc[\"corners\"].T, c='whitesmoke')\n",
    "\n",
    "            # background unit cell shape\n",
    "            plt.fill(*fd['corners'].T, c='lightgrey')  # c='tab:orange')\n",
    "\n",
    "            # plot filled triangles\n",
    "            temp = all_mesh_points[all_elements]\n",
    "            temp = np.transpose(temp, axes=[0,2,1])\n",
    "            temp = temp.reshape(-1, temp.shape[-1])\n",
    "            temp = temp[..., [0,3,1,4,2,5]]  # order the nodes counterclockwise\n",
    "            plt.fill(*temp, alpha=0.5)  # c='whitesmoke')\n",
    "\n",
    "            # plot points\n",
    "            plt.scatter(*all_mesh_points.T, s=1, zorder=10, c='black')\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_unit_cell_mesh.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "\n",
    "            plt.close()\n",
    "\n",
    "        # %%\n",
    "        # Plot unit cell 2×2\n",
    "        if figures in [1,2]:\n",
    "            fig, ax = plt.subplots(figsize=(7,7))\n",
    "            # ax.set_title(f'{group} ({shape})')\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            # background fundamental domain shape\n",
    "            ax.fill(*uc[\"corners\"].T, c='whitesmoke', zorder=-11)\n",
    "\n",
    "            # background fundamental domain shape\n",
    "            ax.fill(*fd['corners'].T, c='lightgrey', zorder=-10)\n",
    "\n",
    "            vecs = uc['lattice vectors']\n",
    "\n",
    "            # loop over vecs[0] translations\n",
    "            for i in range(2):\n",
    "                # loop over vecs[1] translations\n",
    "                for j in range(2):\n",
    "                    points_temp = hf.translate_points(all_mesh_points, i*vecs[0]+j*vecs[1])\n",
    "\n",
    "                    # plot filled triangles\n",
    "                    temp = points_temp[all_elements]\n",
    "                    temp = np.transpose(temp, axes=[0,2,1])\n",
    "                    temp = temp.reshape(-1, temp.shape[-1])\n",
    "                    temp = temp[..., [0,3,1,4,2,5]]\n",
    "                    if i == 0 and j == 0:\n",
    "                        plt.fill(*temp)  #, alpha=0.5)\n",
    "                    else:\n",
    "                        plt.fill(*temp, c='tab:orange')\n",
    "\n",
    "                    # ax.scatter(*points_temp.T, alpha=0.5, s=50)  #, c='tab:orange')\n",
    "                    # x, y = np.transpose(points_temp[uc[\"edges\"].T], axes=[2,0,1])\n",
    "                    # edges0 = ax.plot(x, y, alpha=0.3, c='tab:red')\n",
    "\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_RVE.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        if verbose:\n",
    "            print('Time for plots:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %%\n",
    "        tol = 1e-5\n",
    "\n",
    "        # find new boundary nodes\n",
    "        mesh_bounds = []\n",
    "        for b_start, b_vec in uc['bounds']:\n",
    "            mesh_bounds.append([])\n",
    "            bools_onbound = hf.iscollinear(all_mesh_points, b_start, b_start+b_vec, tol_g=1e-5)\n",
    "            mesh_bounds[-1] = np.where(bools_onbound)[0]\n",
    "\n",
    "            # sort them in the correct order\n",
    "            if np.abs(b_vec[0]) > tol:\n",
    "                temp = np.argsort(all_mesh_points[mesh_bounds[-1], 0]/b_vec[0])\n",
    "            elif np.abs(b_vec[1]) > tol:\n",
    "                temp = np.argsort(all_mesh_points[mesh_bounds[-1], 1]/b_vec[1])\n",
    "            else:\n",
    "                raise ValueError(f\"bad value of b_vec: {b_vec}\")\n",
    "            mesh_bounds[-1] = mesh_bounds[-1][temp].tolist()\n",
    "\n",
    "        mesh_bounds\n",
    "\n",
    "        # %% Plot to check boundary nodes\n",
    "        if figures == 2:\n",
    "            fig, ax = plt.subplots(figsize=(7,7))\n",
    "            # ax.set_title(f'{group} ({shape})')\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            plt.scatter(*all_mesh_points.T, alpha=0.3, s=5)\n",
    "\n",
    "            temp = all_elements[:, [0,3,1,4,2,5,0]]\n",
    "            x, y = np.transpose(all_mesh_points[temp.T], axes=[2,0,1])\n",
    "            edges0 = plt.plot(x, y, alpha=0.1, c='tab:red', zorder=-1)\n",
    "\n",
    "            for inds in mesh_bounds:\n",
    "                if verbose:\n",
    "                    print(len(inds))\n",
    "                plt.scatter(*all_mesh_points[inds].T, s=5)\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_check_boundary_nodes.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        if verbose:\n",
    "            print('Time for finding and plotting boundary nodes:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% flip mirrored elements\n",
    "        temp = all_mesh_points[all_elements]\n",
    "        temp = temp[..., [0,3,1,4,2,5], :]\n",
    "        signed_areas = hf.polygon_area(temp, signed=True)\n",
    "        print(\"all_elements[signed_areas < 0].shape:\")\n",
    "        print(all_elements[signed_areas < 0].shape)\n",
    "        all_elements[signed_areas < 0] = all_elements[signed_areas < 0][:, [2,1,0,4,3,5]]\n",
    "\n",
    "        if verbose:\n",
    "            print('Time to find and flip mirrored elements:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% Save things\n",
    "        for i in range(len(unique_holes)):\n",
    "            try:\n",
    "                unique_holes[i]['poly'] = unique_holes[i]['poly'].coords\n",
    "            except AttributeError as e:\n",
    "                if verbose:\n",
    "                    print(repr(e))\n",
    "\n",
    "        for i in range(len(unique_holes)):\n",
    "            try:\n",
    "                del unique_holes[i]['skel']\n",
    "            except KeyError as e:\n",
    "                if verbose:\n",
    "                    print(repr(e))\n",
    "\n",
    "        with open(hf.new_path(os.path.join(save_dir, f'{name}.pkl')), 'wb') as f:\n",
    "            pickle.dump({'uc': uc, 'fd': fd,\n",
    "                        'p': mesh_points, 't': elements,\n",
    "                        'p_all': all_mesh_points, 't_all': all_elements,\n",
    "                        'boundary_inds': mesh_bounds,\n",
    "                        'unique_holes': unique_holes,\n",
    "                    }, f)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Time for saving: {time.time() - time_temp:.4} seconds')\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% [markdown]\n",
    "        # turn unit cell into RVE: tile 2×2\n",
    "        all_mesh_points2 = np.concatenate((all_mesh_points,\n",
    "                                    all_mesh_points + uc['lattice vectors'][0],\n",
    "                                    all_mesh_points + uc['lattice vectors'][1],\n",
    "                                    all_mesh_points + uc['lattice vectors'][0] + uc['lattice vectors'][1],\n",
    "                                    ), axis=0)\n",
    "        n = len(all_mesh_points)\n",
    "        all_elements2 = np.concatenate((all_elements,\n",
    "                                        all_elements + n,\n",
    "                                        all_elements + 2*n,\n",
    "                                        all_elements + 3*n,\n",
    "                                        ), axis=0)\n",
    "\n",
    "        inds_per_fd2 = np.tile(inds_per_fd, reps=(4, 1, 1))\n",
    "        inds_per_fd2 += np.arange(4).reshape(-1, 1, 1)*n\n",
    "        if verbose:\n",
    "            print('inds_per_fd2.shape', inds_per_fd2.shape)\n",
    "\n",
    "        mesh_bounds2 = [mesh_bounds,\n",
    "                        [(np.array(mb) + n).tolist() for mb in mesh_bounds],\n",
    "                        [(np.array(mb) + 2*n).tolist() for mb in mesh_bounds],\n",
    "                        [(np.array(mb) + 3*n).tolist() for mb in mesh_bounds],]\n",
    "\n",
    "        # %% Deduplicate (again)\n",
    "        start_time_dedup = time.time()\n",
    "        all_mesh_points4, inds, inv, c = hf.uniquetol(all_mesh_points2, tol=1e-5, return_counts=True, return_index=True, return_inverse=True, axis=0)\n",
    "        if verbose:\n",
    "            print(f'Time for deduplication: {time.time() - start_time_dedup:.4} seconds')\n",
    "        all_elements4 = inv[all_elements2]\n",
    "        inds_per_fd4 = inv[inds_per_fd2]\n",
    "\n",
    "        for i in range(len(mesh_bounds2)):\n",
    "            for j in range(len(mesh_bounds2[i])):\n",
    "                mesh_bounds2[i][j] = inv[mesh_bounds2[i][j]]\n",
    "\n",
    "        if verbose:\n",
    "            print('Time to tile into RVE:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %%\n",
    "        # Plot RVE, with unit cell boundaries\n",
    "        if figures == 2:\n",
    "            fig, ax = plt.subplots(figsize=(7,7))\n",
    "            # ax.set_title(f'{group} ({shape})')\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            # Plot after deduplication\n",
    "            temp = all_mesh_points4[all_elements4]\n",
    "            temp = np.transpose(temp, axes=[0,2,1])\n",
    "            temp = temp[..., [0,3,1,4,2,5]]\n",
    "            temp = temp.reshape(-1, temp.shape[-1])\n",
    "            plt.fill(*temp, alpha=0.5)  #, c='tab:orange')\n",
    "\n",
    "            for mb in mesh_bounds2:\n",
    "                for mb2 in mb:\n",
    "                    plt.scatter(*all_mesh_points4[mb2].T, s=5, zorder=11)\n",
    "\n",
    "            plt.scatter(*all_mesh_points4[inds_per_fd4[0][0]].T, s=1, zorder=10, c='black')\n",
    "            plt.scatter(*all_mesh_points4[inds_per_fd4[1][0]].T, s=1, zorder=10, c='black')\n",
    "\n",
    "            # plt.scatter(*all_mesh_points4.T, s=1, zorder=10)\n",
    "            plt.gca().set_aspect('equal')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_RVE_with_uc_boundaries.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        # %%\n",
    "        if figures == 2:\n",
    "            # Plot counts\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            # ax.set_title(f'{group} ({shape})')\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            temp = all_mesh_points4[all_elements4]\n",
    "            temp = np.transpose(temp, axes=[0,2,1])\n",
    "            temp = temp[..., [0,3,1,4,2,5]]\n",
    "            temp = temp.reshape(-1, temp.shape[-1])\n",
    "            plt.fill(*temp, c='whitesmoke')\n",
    "            plt.title('counts per point, should be =/= 1 at and only at overlapping unit cell boundaries')\n",
    "\n",
    "            for count in np.unique(c):\n",
    "                plt.scatter(*all_mesh_points4[c == count].T, s=count*5, zorder=10, label=count)\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.legend(title='count', loc=1)\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_counts.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        if verbose:\n",
    "            print('Time for plots:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %%\n",
    "        # meshbounds: find new boundary nodes of RVE (old boundary points and copies thereof, minus the deduplicated ones)\n",
    "        mesh_bounds4 = [[] for asdf in mesh_bounds2[0]]\n",
    "\n",
    "        # iterate over unit cells\n",
    "        for i in range(len(mesh_bounds2)):\n",
    "            # iterate over direction of boundary\n",
    "            # oblique: bottom, right, top, left\n",
    "            # hexagonal: bottom, bottomright, topright, top, topleft, bottomleft\n",
    "            for j in range(len(mesh_bounds2[i])):\n",
    "                # check if it's an internal boundary by checking if all of the nodes had duplicates\n",
    "                if (c[mesh_bounds2[i][j]] == 1).any():\n",
    "                    mesh_bounds4[j].extend(mesh_bounds2[i][j])\n",
    "\n",
    "        # %%\n",
    "        # Check if number of boundary nodes is consistent with the unit cell\n",
    "        for i in range(len(mesh_bounds4)):\n",
    "            mesh_bounds4[i] = np.unique(mesh_bounds4[i]).tolist()\n",
    "            if hf.wallpaper_groups[group]['unit cell shape'] == 'hexagon':\n",
    "                len_new = len(mesh_bounds4[i])\n",
    "                len_old = len(mesh_bounds2[0][i])\n",
    "                assert 2*len_old-2 <= len_new <= 3*len_old, 'boundaries are the wrong size!'\n",
    "            elif hf.wallpaper_groups[group]['unit cell shape'] == 'parallelogram':\n",
    "                len_new = len(mesh_bounds4[i])\n",
    "                len_old = len(mesh_bounds2[0][i])\n",
    "                assert 2*len_old-2 <= len_new <= 2*len_old, 'boundaries are the wrong size!'\n",
    "            else:\n",
    "                raise ValueError(f\"shape {hf.wallpaper_groups[group]['unit cell shape'] } not implemented\")\n",
    "\n",
    "        # %%\n",
    "        # sort boundary nodes in the correct order\n",
    "        for i, mb in enumerate(mesh_bounds4):\n",
    "            coords = all_mesh_points4[mb]\n",
    "\n",
    "            # sort by whichever has a larger difference: x- or y-coordinate\n",
    "            x_diff = np.max(coords[:, 0]) - np.min(coords[:,0])\n",
    "            y_diff = np.max(coords[:, 1]) - np.min(coords[:,1])\n",
    "\n",
    "            if group == 'p3' or group == 'p3m1':\n",
    "                temp2 = np.einsum('i,ji->j', uc['bounds'][i][1], coords)\n",
    "                mesh_bounds4[i] = np.array(mesh_bounds4[i])[np.argsort(temp2)]\n",
    "                if i >= 3:\n",
    "                    mesh_bounds4[i] = np.flip(mesh_bounds4[i], axis=0)\n",
    "            else:\n",
    "                if x_diff > y_diff:\n",
    "                    mesh_bounds4[i] = np.array(mesh_bounds4[i])[np.argsort(coords[:, 0])]\n",
    "                # else sort by y-coordinate\n",
    "                else:\n",
    "                    mesh_bounds4[i] = np.array(mesh_bounds4[i])[np.argsort(coords[:, 1])]\n",
    "\n",
    "        # in the case of a hexagonal unit cell, the third boundary has a different order for the source vs the image nodes (reverse order of thirds)\n",
    "        if group == 'p3':\n",
    "            n = len(mesh_bounds4[3])//3\n",
    "            mesh_bounds4[3] = np.concatenate((mesh_bounds4[3][2*n:],\n",
    "                                            mesh_bounds4[3][n:2*n],\n",
    "                                            mesh_bounds4[3][:n]), axis=0)\n",
    "\n",
    "        if group == 'p3m1':\n",
    "            n = len(mesh_bounds4[5])//3\n",
    "            mesh_bounds4[5] = np.concatenate((mesh_bounds4[5][2*n:],\n",
    "                                            mesh_bounds4[5][n:2*n],\n",
    "                                            mesh_bounds4[5][:n]), axis=0)\n",
    "\n",
    "        if verbose:\n",
    "            print('Time to get RVE boundaries:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% Plot to check boundaries\n",
    "        if figures == 2:\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            # ax.set_title(f'{group} ({shape})')\n",
    "            fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "            temp = all_mesh_points4[all_elements4]\n",
    "            temp = np.transpose(temp, axes=[0,2,1])\n",
    "            temp = temp[..., [0,3,1,4,2,5]]\n",
    "            temp = temp.reshape(-1, temp.shape[-1])\n",
    "            plt.fill(*temp, c='whitesmoke')\n",
    "\n",
    "            for mb in mesh_bounds4:\n",
    "                plt.scatter(*all_mesh_points4[mb].T, s=5, zorder=11, alpha=0.5)\n",
    "                plt.scatter(*all_mesh_points4[mb][:10].T, s=2, zorder=11)\n",
    "\n",
    "            plt.scatter(*all_mesh_points4.T, s=1, zorder=10, c='black')\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.title('Check boundaries')\n",
    "\n",
    "            path1 = hf.new_path(os.path.join(save_dir, f'fig_{fig_nr}_check_boundaries.png'))\n",
    "            fig_nr += 1\n",
    "            plt.axis('off')\n",
    "            fig.savefig(path1)\n",
    "            plt.close()\n",
    "\n",
    "        if verbose:\n",
    "            print('Time for plotting boundaries:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        print('create & deduplicate edges for crossing edges check')\n",
    "        t = all_elements4\n",
    "        edges = np.vstack((t[:, [0, 3]],\n",
    "                    t[:, [3, 1]],\n",
    "                    t[:, [1, 4]],\n",
    "                    t[:, [4, 2]],\n",
    "                    t[:, [2, 5]],\n",
    "                    t[:, [5, 0]]))\n",
    "\n",
    "        edges2 = np.sort(edges, axis=-1)\n",
    "        edges3, inv, counts = np.unique(edges2, axis=0, return_inverse=True, return_counts=True)\n",
    "\n",
    "        if np.any(counts > 2):\n",
    "            raise ValueError('Some edges are used more than twice')\n",
    "\n",
    "        if verbose:\n",
    "            print('Time to create and deduplicate edges:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "        # %% save to matlab stuff\n",
    "        # needed:\n",
    "        # * nodes: xyz coordinates of the nodes, shape [nr of nodes, 3] (z-coordinate can be zero)\n",
    "        # * nNodes: nr of nodes (integer)\n",
    "        # elements: indices of nodes defining elements, shape [nr of elements, 6], elements 0, 1, 2 are the corner nodes in counterclockwise order, 3,4,5 are the mid-edge nodes also in counterclockwise order\n",
    "        # * elemMats: material of each element (all the same, can all be 1), shape [nr of elements, 1]\n",
    "        # * nelems: nr of elements\n",
    "        # FE2: 1×1 struct, contains:\n",
    "        #   FE2.V: volume of RVE\n",
    "        #   FE2.periodicSourceNodes: list of independent boundary + corner nodes (?)\n",
    "        #   FE2.periodicImageNodes: list of corresponding dependent boundary + corner nodes\n",
    "        # which nodes correspond to which fundamental domain\n",
    "\n",
    "        transforms = copy.deepcopy(uc['transforms'])\n",
    "        # to do: transforms to numerical form\n",
    "        for i, temp in enumerate(uc['transforms']):\n",
    "            for j, temp2 in enumerate(temp):\n",
    "                for k, temp3 in enumerate(temp2):\n",
    "                    try:\n",
    "                        transforms[i][j][k] = eval(temp3)\n",
    "                    except NameError:\n",
    "                        transforms[i][j][k] = temp3\n",
    "        if verbose:\n",
    "            print(transforms)\n",
    "\n",
    "        scipy.io.savemat(hf.new_path(os.path.join(save_dir, f'{name}.mat')),\n",
    "                        {'p': all_mesh_points4,\n",
    "                        't': all_elements4,\n",
    "                        'boundary_inds': mesh_bounds4,\n",
    "                        'inds_per_fd': inds_per_fd4,\n",
    "                        'lattice_vectors': uc['lattice vectors'],\n",
    "                        'transforms': transforms,\n",
    "                        'a1': fd['a1'],\n",
    "                        'a2': fd['a2'],\n",
    "                        'volume_fraction': vol_frac2,\n",
    "                        })\n",
    "        print('Saved to .mat file')\n",
    "\n",
    "        # %%\n",
    "        print('Volume fraction based on mesh:', f'{vol_frac2*100:.1f}%')\n",
    "        print(f'Total time to generate new material: {time.time()-start_time:.4} seconds')\n",
    "\n",
    "        print('Points shape:', all_mesh_points4.shape)\n",
    "        print('Elements shape:', all_elements4.shape)\n",
    "\n",
    "        with open(hf.new_path(os.path.join(save_dir, 'info.txt')), 'w') as f:\n",
    "            f.write(f'Volume fraction: {vol_frac2*100:.1f}%\\n')\n",
    "            f.write(f'Total time: {time.time()-start_time:.4} seconds\\n')\n",
    "\n",
    "        if verbose:\n",
    "            print('Time for saving:', time.time()-time_temp)\n",
    "            time_temp = time.time()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error in {file}: {repr(e)}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the meshes generated above in the matlab code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import results\n",
    "After the matlab code has been used to perform a simulation using each of the mesh files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import helper_funcs as hf\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_base = 'p4_square_2024-05-22_15-01-53.190117'\n",
    "# geom_base = 'p4m_square_2024-05-22_15-08-35.472754'\n",
    "# geom_base = 'p6_hexagonal_2024-05-22_15-52-16.388326'\n",
    "# geom_base = 'pg_rectangular_2024-05-22_14-21-22.169238'\n",
    "\n",
    "results_path = r'path_to_matlab_results' + geom_base\n",
    "\n",
    "# path where the meshes were saved\n",
    "geometries_path = r'mesh_convergence_' + geom_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = []\n",
    "for file in os.listdir(results_path):\n",
    "    if file.endswith('.mat') and not file.endswith('_specialnodes.mat'):\n",
    "        geoms.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by hmax\n",
    "\n",
    "hmax = np.array([float(geom.split('_')[1]) for geom in geoms])\n",
    "\n",
    "inds = np.argsort(-hmax)\n",
    "\n",
    "hmax = np.array(hmax)[inds]\n",
    "geoms = np.array(geoms)[inds]\n",
    "\n",
    "print(hmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 0.00781 <= hmax < 0.25\n",
    "inds = np.logical_and(hmax >= 0.00781, hmax < 0.25)  # 0.00781\n",
    "hmax = hmax[inds]\n",
    "geoms = geoms[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "rerun_found = False\n",
    "data_all = []\n",
    "for g, geom in enumerate(geoms):\n",
    "    print(f'======= {g}, {geom} =======')\n",
    "    # ====================== LOAD SIMULATION DATA ======================\n",
    "    data = {'simulations': {},\n",
    "            'time_steps': {},\n",
    "            'geometry': {'fundamental_domain': {}, 'unit_cell': {}},\n",
    "            'mesh': {'fundamental_domain': {}, 'unit_cell': {}, 'RVE': {}}\n",
    "            }\n",
    "    matfile = os.path.join(results_path, geom + '.mat')\n",
    "    data_from_mat = sio.loadmat(matfile)\n",
    "    for key in data_from_mat['data_sim'].dtype.names:\n",
    "        data['simulations'][key] = data_from_mat['data_sim'][key][0, 0]\n",
    "    for key in data_from_mat['data_ts'].dtype.names:\n",
    "        data['time_steps'][key] = data_from_mat['data_ts'][key][0, 0]\n",
    "    print('errorFlag:', data['simulations']['errorFlag'])\n",
    "\n",
    "    # change from Matlab 1-indexing to Python 0-indexing\n",
    "    data['time_steps']['traj'] -= 1\n",
    "\n",
    "    # reshuffle P\n",
    "    data['time_steps']['P'] = data['time_steps']['P'].reshape(-1, 4, order='F')[:, [0, 2, 3, 1]].reshape(-1,2,2)\n",
    "    # reshuffle D\n",
    "    data['time_steps']['D'] = data['time_steps']['D'].reshape(-1, 4, 4, order='F')[:, [[0], [2], [3], [1]], [[0, 2, 3, 1]]].reshape(-1, 2, 2, 2, 2)\n",
    "\n",
    "    # rename keys\n",
    "    data['time_steps']['trajectory'] = data['time_steps'].pop('traj')\n",
    "    if 'bifurcMode' not in data['time_steps']:\n",
    "        print('!! Warning !! No bifurcation mode data found')\n",
    "        errors.append([geom, 'No bifurcation mode data found', 12])\n",
    "    else:\n",
    "        data['time_steps']['bifurcation_mode'] = data['time_steps'].pop('bifurcMode')\n",
    "    data['simulations']['error_flag'] = data['simulations'].pop('errorFlag')\n",
    "    data['time_steps']['is_bifurcation_point'] = data['time_steps'].pop('bifurc')\n",
    "\n",
    "    if len(data['time_steps']['F']) == 0:\n",
    "        print('!! Warning !! No simulations found')\n",
    "        errors.append([geom, 'No simulations found', len(data['simulations']['F_final'])])\n",
    "        data_all.append([])\n",
    "        continue\n",
    "\n",
    "    # reshape/remove trailing dimension\n",
    "    for key in ['computation_time', 'error_flag']:\n",
    "        data['simulations'][key] = data['simulations'][key][:, 0]\n",
    "    data['time_steps']['trajectory'] = data['time_steps']['trajectory'][:, 0]\n",
    "    data['time_steps']['is_bifurcation_point'] = data['time_steps']['is_bifurcation_point'][:, 0]\n",
    "\n",
    "    # reshape bifurcation mode\n",
    "    if 'bifurcation_mode' in data['time_steps']:\n",
    "        data['time_steps']['bifurcation_mode'] = data['time_steps']['bifurcation_mode'][0] # remove singleton dimension\n",
    "        for i, mode in enumerate(data['time_steps']['bifurcation_mode']):\n",
    "            if mode.shape == (0, 0):\n",
    "                data['time_steps']['bifurcation_mode'][i] = None\n",
    "            else:\n",
    "                data['time_steps']['bifurcation_mode'][i] = mode.reshape(-1, 2)\n",
    "\n",
    "    lengths = [len(data['time_steps'][key]) for key in data['time_steps']]\n",
    "    if len(set(lengths)) != 1:\n",
    "        print('!! Warning !! Not all time steps have the same length')\n",
    "        print(lengths)\n",
    "        errors.append([geom, 'Missing time steps', max(lengths) - min(lengths)])\n",
    "        data_all.append([])\n",
    "        continue\n",
    "    print('Nr of time steps:', len(data['time_steps']['F']))\n",
    "    print('Nr of nodes:', data['time_steps']['microfluctuation'].shape[1])\n",
    "\n",
    "    # ====================== LOAD SPECIAL NODES DATA ======================\n",
    "    matfile = os.path.join(results_path, geom + '_specialnodes.mat')\n",
    "    data_from_mat_specialnodes = sio.loadmat(matfile)\n",
    "    # change from Matlab 1-indexing to Python 0-indexing\n",
    "    data['mesh']['RVE']['fixed_node'] = data_from_mat_specialnodes['fixed_node'][0,0]-1\n",
    "    data['mesh']['RVE']['source_nodes'] = data_from_mat_specialnodes['source_nodes'][:, 0]-1\n",
    "    data['mesh']['RVE']['image_nodes'] = data_from_mat_specialnodes['image_nodes'][:, 0]-1\n",
    "\n",
    "    # ====================== LOAD GEOMETRY DATA (.mat) ======================\n",
    "    # load data that was sent to matlab\n",
    "    path = os.path.join(geometries_path, geom + '.mat')\n",
    "    data_to_mat = sio.loadmat(path)\n",
    "\n",
    "    data['mesh']['RVE']['p'] = data_to_mat['p']\n",
    "    data['mesh']['RVE']['t'] = data_to_mat['t']\n",
    "    data['mesh']['RVE']['boundary_inds'] = data_to_mat['boundary_inds']\n",
    "    data['mesh']['RVE']['inds_per_fd'] = data_to_mat['inds_per_fd']\n",
    "    data['mesh']['RVE']['volume_fraction'] = data_to_mat['volume_fraction'][0,0]\n",
    "\n",
    "    # check dtype\n",
    "    if data['mesh']['RVE']['boundary_inds'].dtype == object:\n",
    "        b = data['mesh']['RVE']['boundary_inds'][0]\n",
    "        data['mesh']['RVE']['boundary_inds'] = [b2[0].tolist() for b2 in b]\n",
    "    else:\n",
    "        data['mesh']['RVE']['boundary_inds'] = data['mesh']['RVE']['boundary_inds'].tolist()\n",
    "\n",
    "    # ====================== LOAD GEOMETRY DATA (.pkl) ======================\n",
    "    # load data from .pkl file from geometry generation\n",
    "    with open(os.path.join(geometries_path, geom + '.pkl'), 'rb') as f:\n",
    "        data_pkl = pickle.load(f)\n",
    "\n",
    "    # add unit cell data\n",
    "    for key, value in data_pkl['uc'].items():\n",
    "        data['geometry']['unit_cell'][key] = value\n",
    "\n",
    "    # rename lattice vectors to lattice_vectors\n",
    "    data['geometry']['unit_cell']['lattice_vectors'] = data['geometry']['unit_cell'].pop('lattice vectors')\n",
    "\n",
    "    # delete equiv_nodes, is equivalent to periodic_nodes\n",
    "    del data['geometry']['unit_cell']['equiv_nodes']\n",
    "\n",
    "    # add fundamental domain data\n",
    "    for key, value in data_pkl['fd'].items():\n",
    "        data['geometry']['fundamental_domain'][key] = value\n",
    "\n",
    "    # delete unnecessary keys\n",
    "    del data['geometry']['fundamental_domain']['points']\n",
    "    del data['geometry']['fundamental_domain']['bound_inds']\n",
    "    del data['geometry']['fundamental_domain']['edges']\n",
    "    del data['geometry']['fundamental_domain']['n_points']\n",
    "    del data['geometry']['fundamental_domain']['n_edges']\n",
    "\n",
    "    # add unique holes data\n",
    "    data['geometry']['unique_faces'] = data_pkl['unique_holes']\n",
    "\n",
    "    uf = data['geometry']['unique_faces']\n",
    "    for elem in uf:\n",
    "        if 'equiv_holes' in elem:\n",
    "            elem['equiv_faces'] = elem.pop('equiv_holes')\n",
    "        if 'all_holes' in elem:\n",
    "            elem['all_faces'] = elem.pop('all_holes')\n",
    "\n",
    "    for elem in data['geometry']['unique_faces']:\n",
    "        # to do: might throw an error if bisectors_x or splint_point_dists are not defined\n",
    "        if 'bisectors_x' in elem:\n",
    "            elem['bisectors_x'] = np.array(elem['bisectors_x'])\n",
    "        if 'spline_point_dists' in elem:\n",
    "            elem['spline_point_dists'] = np.array(elem['spline_point_dists'])\n",
    "\n",
    "    data['mesh']['fundamental_domain']['p'] = data_pkl['p']\n",
    "    data['mesh']['fundamental_domain']['t'] = data_pkl['t']\n",
    "\n",
    "    data['mesh']['unit_cell']['p'] = data_pkl['p_all']\n",
    "    data['mesh']['unit_cell']['t'] = data_pkl['t_all']\n",
    "    data['mesh']['unit_cell']['boundary_inds'] = data_pkl['boundary_inds']\n",
    "\n",
    "    # ====================== CREATE convenient quantities ======================\n",
    "    # Calculate position of points at each time step\n",
    "    F = data['time_steps']['F']  # shape (n_time_steps, 2, 2)\n",
    "    x_0 = data['mesh']['RVE']['p']  # shape (n_points, 2)\n",
    "    w = data['time_steps']['microfluctuation']  # shape (n_time_steps, n_points, 2)\n",
    "    x = np.einsum('ijk,lk->ilj', F, x_0) + w\n",
    "    data['time_steps']['x'] = x\n",
    "\n",
    "    # Create edges\n",
    "    # turn the elements into edges and deduplicate them\n",
    "    t = data['mesh']['RVE']['t']\n",
    "    edges = np.vstack((t[:, [0, 3]],\n",
    "                    t[:, [3, 1]],\n",
    "                    t[:, [1, 4]],\n",
    "                    t[:, [4, 2]],\n",
    "                    t[:, [2, 5]],\n",
    "                    t[:, [5, 0]]))\n",
    "    edges2 = np.sort(edges, axis=1)\n",
    "    edges3, counts = np.unique(edges2, axis=0, return_counts=True)\n",
    "    data['mesh']['RVE']['edges'] = edges3\n",
    "\n",
    "    # find all edges that are not shared by two triangles: boundary edges\n",
    "    # (either boundary of the RVE of boundary of a hole)\n",
    "    # for each edge in the boundary, check if both nodes are in the same array in boundary_inds\n",
    "    # if so, it is a unit cell boundary edge\n",
    "    b_edges = edges3[counts!=2]\n",
    "    bools = np.zeros(len(b_edges), dtype=bool)\n",
    "    # print(len(data['mesh']['RVE']['boundary_inds']), len(data['mesh']['RVE']['boundary_inds'][0]))\n",
    "    for b in data['mesh']['RVE']['boundary_inds']:\n",
    "        bools[np.isin(b_edges[:, 0], b)*np.isin(b_edges[:, 1], b)] = True\n",
    "    bools2 = np.zeros(len(edges3), dtype=bool)\n",
    "    bools2[counts!=2] = bools\n",
    "    data['mesh']['RVE']['boundary_edges_inds'] = np.where(bools2)[0]\n",
    "\n",
    "    # select hole boundary edges\n",
    "    # (edges that are boundary edges but not unit cell boundary edges)\n",
    "    bools3 = np.zeros(len(edges3), dtype=bool)\n",
    "    bools3[counts!=2] = True  # all boundary edges\n",
    "    bools3[bools2] = False     # remove unit cell boundary edges, leaving only hole boundary edges  #!! edge case: if a hole boundary edge is also a unit cell boundary edge, this will go wrong!!\n",
    "    data['mesh']['RVE']['hole_boundary_edges_inds'] = np.where(bools3)[0]\n",
    "\n",
    "    # ====================== REMOVE CONTACT ======================\n",
    "    edges = data['mesh']['RVE']['edges']\n",
    "    hb_inds = data['mesh']['RVE']['hole_boundary_edges_inds']\n",
    "    hb_edges = edges[hb_inds]\n",
    "    # only use coordinates of hole boundary nodes and edges at the hole boundary\n",
    "    hb_nodes, hb_edges = np.unique(hb_edges, return_inverse=True)\n",
    "    hb_edges = hb_edges.reshape(-1, 2)\n",
    "    hb_x = data['time_steps']['x'][:, hb_nodes]\n",
    "\n",
    "    # specify end and start of each trajectory\n",
    "    traj = data['time_steps']['trajectory']\n",
    "    n_trajs = np.max(traj)+1\n",
    "    start_inds = np.concatenate(([0], np.where(traj[:-1] != traj[1:])[0]+1))\n",
    "    end_inds = np.concatenate((start_inds[1:], [len(traj)]))\n",
    "\n",
    "    ends_in_contact = np.zeros(n_trajs, dtype=bool)\n",
    "    i = 0\n",
    "    while i < len(traj):\n",
    "        # print(i)\n",
    "        traj_i = traj[i]\n",
    "\n",
    "        # Get the positions of the nodes\n",
    "        x = data['time_steps']['x'][i]\n",
    "        hb_x_i = hb_x[i]\n",
    "\n",
    "        # check if a pair of edges intersects\n",
    "        cr = hf.crossing_edges(hb_x_i, hb_edges)\n",
    "\n",
    "        if cr.size > 0:\n",
    "            ends_in_contact[traj_i] = True\n",
    "            # print(f'i={i}, traj={traj[i]}, contact detected')\n",
    "\n",
    "            end_inds[traj_i] = i # this trajectory ends early\n",
    "            if traj_i == n_trajs-1: # last trajectory, break for loop\n",
    "                break\n",
    "            else: # skip rest of the time steps of this trajectory, go to start of next trajectory\n",
    "                if i > start_inds[traj_i+1]:\n",
    "                    raise ValueError('i should go back to a previous time step, which makes no sense')\n",
    "                i = start_inds[traj_i+1]\n",
    "\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    inds_to_keep = np.concatenate([np.arange(i,j) for i,j in zip(start_inds, end_inds)])\n",
    "    print(f'Trajectory lengths: {end_inds-start_inds}')\n",
    "    error2 = data['simulations']['error_flag']\n",
    "    error2[ends_in_contact] = False\n",
    "    print(f'Error before contact: {error2}')\n",
    "\n",
    "    if np.any(end_inds - start_inds <= 2):\n",
    "        print('!! Warning !! One or more trajectories have length <= 2')\n",
    "        errors.append([geom, 'Trajectories of length <= 2 after removing contact', np.sum(end_inds-start_inds <= 2), np.where(end_inds-start_inds <= 2)[0]])\n",
    "    if np.any(error2):\n",
    "\n",
    "        print('!! Warning !! One or more trajectories still end in an error when contact is removed')\n",
    "        n_err = error2.sum()\n",
    "        errors.append([geom, 'Error remains after removing contact', n_err, np.where(error2)[0]])\n",
    "\n",
    "    for key in data['time_steps']:\n",
    "        data['time_steps'][key] = data['time_steps'][key][inds_to_keep]\n",
    "\n",
    "    data['simulations']['error_flag'] = error2.astype(bool)\n",
    "    data['simulations']['ends_in_contact'] = ends_in_contact.astype(bool)\n",
    "\n",
    "    # sum up is_bifurcation_point per trajectory\n",
    "    inds_slice = np.nonzero(np.diff(data['time_steps']['trajectory']))[0] + 1\n",
    "    inds_slice = np.insert(inds_slice, 0, 0)  # add zero at the beginning\n",
    "    data['simulations']['contains_bifurcation'] = np.add.reduceat(data['time_steps']['is_bifurcation_point'], inds_slice).astype(bool)\n",
    "\n",
    "    data_all.append(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convenient quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.array([data['simulations']['error_flag'][0] if 'simulations' in data else True for data in data_all])\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mesh with the lowest hmax (=clmax) value to use as ground truth\n",
    "hmax_temp = hmax.copy()\n",
    "hmax_temp[err] = np.inf\n",
    "ground_truth_i = np.argmin(hmax_temp)\n",
    "print(ground_truth_i)\n",
    "print(hmax[ground_truth_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find geometry closest to the actual hmax (0.040824829046386304)\n",
    "chosen_i = np.where(np.array(hmax)>0.04)[0][-1]\n",
    "chosen_i\n",
    "hmax[chosen_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = data_all[ground_truth_i]['time_steps']['Time'][-1, 0]\n",
    "tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\n",
    "    [\n",
    "        data['time_steps']['Time'][0, 0],\n",
    "        data['time_steps']['Time'][-1, 0],\n",
    "        data['simulations']['ends_in_contact'][0],\n",
    "        data['simulations']['error_flag'][0],\n",
    "    ] if 'time_steps' in data else [-1, -1, -1, -1] for data in data_all]\n",
    "for i, temp_temp in enumerate(temp):\n",
    "    begin, end, contact, error_flag = temp_temp\n",
    "    # print(begin, end, contact, error_flag)\n",
    "    print(f'hmax={hmax[i]:7.3}  {begin:.2f} - {end:.2f}, ends in {\"contact\"*bool(contact)}{\"error\"*bool(error_flag)}{\"nothing special\"*(not contact and not bool(error_flag))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(data_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the stress components during trajectory 1\n",
    "fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "F = data_all[0]['simulations']['F_final']\n",
    "fig.suptitle(f'At Time=1.0, F=[[{F[0,0]:.3}, {F[0,1]:.3}], [{F[1,0]:.3}, {F[1,1]:.3}]]')\n",
    "\n",
    "for k, data in enumerate(data_all):\n",
    "    geom = geoms[k][5:-3]\n",
    "    Time = data['time_steps']['Time']\n",
    "    P = data['time_steps']['P']\n",
    "\n",
    "    for ax, [i,j] in zip(axes.flatten(), [[0,0], [0,1], [1,0], [1,1]]):\n",
    "        ax.plot(Time, P[:, i, j], label=f'{float(geom):.3}', marker='o', c=colors[k])\n",
    "\n",
    "    # add a vertical line at each bifurcation point\n",
    "    t_bif = np.where(data['time_steps']['is_bifurcation_point'])[0]\n",
    "    for t in t_bif:\n",
    "        for ax in axes.flatten():\n",
    "            ax.axvline(Time[t], c=colors[k], linestyle='--') #, label='bifurcation')\n",
    "\n",
    "for ax, [i,j] in zip(axes.flatten(), [[0,0], [0,1], [1,0], [1,1]]):\n",
    "    ax.set_ylabel('$P_{' + str(i+1) + str(j+1) + '}$')\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', title='hmax')\n",
    "\n",
    "# add more space in between the subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolationsP = []\n",
    "for data in data_all:\n",
    "    Time = data['time_steps']['Time'][:, 0]\n",
    "    P = data['time_steps']['P']\n",
    "    Time2 = np.arange(0, tmax, 0.1)\n",
    "    spl = interp1d(Time, P, axis=0, kind='linear', fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "    vals = spl(Time2)\n",
    "    interpolationsP.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frob_errorP = []\n",
    "rel_frob_errP = []\n",
    "frob_gtP = np.linalg.norm(interpolationsP[ground_truth_i], axis=(1,2))\t# frobenius norm of ground truth\n",
    "for vals in interpolationsP:\n",
    "    frob_errorP.append(np.linalg.norm(vals - interpolationsP[ground_truth_i], axis=(1,2)))\n",
    "    rel_frob_errP.append(frob_errorP[-1] / frob_gtP\n",
    ")\n",
    "frob_errorP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the stress components during trajectory 1\n",
    "fig, axes = plt.subplots(2,2, figsize=(8,8))\n",
    "F = data_all[0]['simulations']['F_final']\n",
    "fig.suptitle(f'At Time=1.0, F=[[{F[0,0]:.3}, {F[0,1]:.3}], [{F[1,0]:.3}, {F[1,1]:.3}]]')\n",
    "\n",
    "for k, data in enumerate(data_all):\n",
    "    geom = geoms[k][5:-3]\n",
    "    Time = data['time_steps']['Time'][:, 0]\n",
    "    P = data['time_steps']['P']\n",
    "\n",
    "    for ax, [i,j] in zip(axes.flatten(), [[0,0], [0,1], [1,0], [1,1]]):\n",
    "        ax.plot(Time2, interpolationsP[k][:, i, j], label=f'{float(geom):.2}', c=colors[k])\n",
    "        ax.scatter(Time, P[:, i, j], c=colors[[k]], s=20)\n",
    "\n",
    "    # add a vertical line at each bifurcation point\n",
    "    t_bif = np.where(data['time_steps']['is_bifurcation_point'])[0]\n",
    "    for t in t_bif:\n",
    "        for ax in axes.flatten():\n",
    "            ax.axvline(Time[t], c=colors[k], linestyle='--')\n",
    "\n",
    "for ax, [i,j] in zip(axes.flatten(), [[0,0], [0,1], [1,0], [1,1]]):\n",
    "    ax.set_ylabel('$P_{' + str(i+1) + str(j+1) + '}$')\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', title='hmax')\n",
    "\n",
    "# add more space in between the subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot error in P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, err in enumerate(rel_frob_errP):\n",
    "    print(i)\n",
    "    if i == ground_truth_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            plt.gca().axvline(Time[t], c=colors[i], linestyle='--') #, label='bifurcation')\n",
    "        continue\n",
    "    print(hmax[i])\n",
    "    plt.plot(Time2, err, c=colors[i], label=f'{hmax[i]:.2}')\n",
    "    if i == chosen_i:\n",
    "        # plot dashed line\n",
    "        plt.plot(Time2, err, c='black', linewidth=4, zorder=-1, linestyle='--')\n",
    "\n",
    "# horizontal line at y=0.05\n",
    "plt.axhline(0.05, c='black', linestyle='--')\n",
    "plt.axhline(0.1, c='black', linestyle=':')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(r'Relative Frobenius error in $\\mathbf{P}$')\n",
    "plt.yscale('log')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, loc='center right', title='hmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = []\n",
    "for i in [0, 1]:\n",
    "    for j in [0, 1]:\n",
    "        for k in [0, 1]:\n",
    "            for l in [0, 1]:\n",
    "                inds.append([i, j, k, l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the stress components during trajectory 1\n",
    "fig, axes = plt.subplots(4,4, figsize=(12,12))\n",
    "F = data_all[0]['simulations']['F_final']\n",
    "fig.suptitle(f'At Time=1.0, F=[[{F[0,0]:.3}, {F[0,1]:.3}], [{F[1,0]:.3}, {F[1,1]:.3}]]')\n",
    "\n",
    "for k, data in enumerate(data_all):\n",
    "    geom = geoms[k][5:-3]\n",
    "    Time = data['time_steps']['Time']\n",
    "    D = data['time_steps']['D']\n",
    "\n",
    "    for ax, [i,j,l,m] in zip(axes.flatten(), inds):\n",
    "        ax.plot(Time, D[:, i, j, l, m], label=geom, marker='o', c=colors[k])\n",
    "\n",
    "    # add a vertical line at each bifurcation point\n",
    "    t_bif = np.where(data['time_steps']['is_bifurcation_point'])[0]\n",
    "    for t in t_bif:\n",
    "        for ax in axes.flatten():\n",
    "            ax.axvline(Time[t], c=colors[k], linestyle='--')\n",
    "\n",
    "for ax, [i,j,l,m] in zip(axes.flatten(), inds):\n",
    "    ax.set_ylabel('$D_{' + str(i+1) + str(j+1) + str(l+1) + str(m+1) +'}$')\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles[::-1], labels[::-1], loc='center right', title='hmax')\n",
    "\n",
    "# add more space in between the subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.5, wspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolationsD = []\n",
    "Time2 = np.arange(0, tmax, 0.1)  #0.0005)\n",
    "\n",
    "for data in data_all:\n",
    "    Time = data['time_steps']['Time'][:, 0]\n",
    "    D = data['time_steps']['D']\n",
    "\n",
    "    spl = interp1d(Time, D, axis=0, kind='linear', fill_value=np.nan, bounds_error=False)\n",
    "    vals = spl(Time2)\n",
    "    interpolationsD.append(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the stress components during trajectory 1\n",
    "fig, axes = plt.subplots(4,4, figsize=(12,12))\n",
    "\n",
    "F = data_all[0]['simulations']['F_final']\n",
    "fig.suptitle(f'At Time=1.0, F=[[{F[0,0]:.3}, {F[0,1]:.3}], [{F[1,0]:.3}, {F[1,1]:.3}]]')\n",
    "\n",
    "for k, data in enumerate(data_all):\n",
    "    geom = geoms[k][5:-3]\n",
    "    Time = data['time_steps']['Time']\n",
    "    D = data['time_steps']['D']\n",
    "\n",
    "    for ax, [i,j,l,m] in zip(axes.flatten(), inds):\n",
    "        ax.scatter(Time, D[:, i, j, l, m], label=f'{float(geom):.2}', marker='o', c=[colors[k]], s=10)\n",
    "\n",
    "    # add a vertical line at each bifurcation point\n",
    "    t_bif = np.where(data['time_steps']['is_bifurcation_point'])[0]\n",
    "    for t in t_bif:\n",
    "        for ax in axes.flatten():\n",
    "            ax.axvline(Time[t], c=colors[k], linestyle='--') #, label='bifurcation')\n",
    "\n",
    "    # add interpolated lines\n",
    "    for ax, [i,j,l,m] in zip(axes.flatten(), inds):\n",
    "        ax.plot(Time2, interpolationsD[k][:, i, j, l, m], c=colors[k])\n",
    "\n",
    "for ax, [i,j,l,m] in zip(axes.flatten(), inds):\n",
    "    ax.set_ylabel('$D_{' + str(i+1) + str(j+1) + str(l+1) + str(m+1) +'}$')\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles[::-1], labels[::-1], loc='center right', title='hmax')\n",
    "\n",
    "# add more space in between the subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.5, wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of only D_1111\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "F = data_all[0]['simulations']['F_final']\n",
    "fig.suptitle(f'At Time=1.0, F=[[{F[0,0]:.3}, {F[0,1]:.3}], [{F[1,0]:.3}, {F[1,1]:.3}]]')\n",
    "\n",
    "for k, data in enumerate(data_all):\n",
    "    geom = geoms[k][5:-3]\n",
    "    Time = data['time_steps']['Time']\n",
    "    D = data['time_steps']['D']\n",
    "\n",
    "    ax.scatter(Time, D[:, 0, 0, 0, 0], label=f'{float(geom):.2}', marker='o', c=[colors[k]], s=10)\n",
    "\n",
    "    # add a vertical line at each bifurcation point\n",
    "    t_bif = np.where(data['time_steps']['is_bifurcation_point'])[0]\n",
    "    for t in t_bif:\n",
    "        ax.axvline(Time[t], c=colors[k], linestyle='--') #, label='bifurcation')\n",
    "\n",
    "    # add interpolated lines\n",
    "    ax.plot(Time2, interpolationsD[k][:, 0, 0, 0, 0], c=colors[k])\n",
    "\n",
    "ax.set_ylabel('$D_{' + str(i+1) + str(j+1) + str(l+1) + str(m+1) +'}$')\n",
    "ax.set_xlabel('Time')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', title='hmax')\n",
    "\n",
    "# add more space in between the subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.5, wspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frob_gtD = np.linalg.norm(data_all[ground_truth_i]['time_steps']['D'][0].reshape(-1, 16), axis=-1)\t# frobenius norm of ground truth, first time step only\n",
    "\n",
    "frob_errorD = []\n",
    "rel_frob_errD = []\n",
    "for vals in interpolationsD:\n",
    "    frob_errorD.append(np.linalg.norm((vals - interpolationsD[ground_truth_i]).reshape(-1, 16), axis=-1))\n",
    "    rel_frob_errD.append(frob_errorD[-1] / frob_gtD)\n",
    "frob_errorD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "plt.figure()\n",
    "for i, err in enumerate(rel_frob_errD):\n",
    "    if i == ground_truth_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            plt.gca().axvline(Time[t], c=colors[i], linestyle='--')\n",
    "        continue\n",
    "\n",
    "    if i == chosen_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            plt.gca().axvline(Time[t], c=colors[i], linestyle='--')\n",
    "\n",
    "    print(hmax[i])\n",
    "    plt.plot(Time2, err, c=colors[i], label=f'{float(hmax[i]):.2}')\n",
    "    if i == chosen_i:\n",
    "        # plot dashed line\n",
    "        plt.plot(Time2, err, c='black', linewidth=4, zorder=-1, linestyle='--')\n",
    "\n",
    "# horizontal line at y=0.05\n",
    "plt.axhline(0.05, c='black', linestyle='--')\n",
    "plt.axhline(0.1, c='black', linestyle=':')\n",
    "\n",
    "# plt.ylim([0, 0.25])\n",
    "plt.xlabel('Time')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Relative Frobenius error in $\\mathbf{D}$')\n",
    "\n",
    "# reverse order of legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, loc='center right', title='hmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot P, D and deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{{amsmath}} \\usepackage{{amssymb}} \\usepackage{{xcolor}}',\n",
    "    'font.size': 14\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3.5))\n",
    "\n",
    "# Plot error in P\n",
    "for i, err in enumerate(rel_frob_errP):\n",
    "    print(i)\n",
    "    if i == ground_truth_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            ax.axvline(Time[t], c=colors[i], linestyle='--') #, label='bifurcation')\n",
    "        continue\n",
    "    print(hmax[i])\n",
    "    ax.plot(Time2, err, c=colors[i], label=f'{hmax[i]:.2}', linestyle='--', marker='o')\n",
    "    if i == chosen_i:\n",
    "        # plot dashed line\n",
    "        ax.plot(Time2, err, c='black', linewidth=4, zorder=-1, )\n",
    "\n",
    "# horizontal line at y=0.05\n",
    "ax.axhline(0.05, c='black', linestyle='--')\n",
    "ax.axhline(0.1, c='black', linestyle=':')\n",
    "\n",
    "ax.set_xlabel(r'$\\tau$')\n",
    "ax.set_ylabel(r'$\\epsilon_{P}$')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='center right', title=r'$cl_{\\textrm{max}}$',\n",
    "          bbox_to_anchor=(1.45, 0.5))\n",
    "\n",
    "plt.subplots_adjust(left=0.2, right=0.7, bottom=0.2, top=0.9)\n",
    "\n",
    "fig.savefig(f'{geom_base}_mesh_convergence_P.pdf', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3.5))\n",
    "\n",
    "# Plot error in D\n",
    "for i, err in enumerate(rel_frob_errD):\n",
    "    if i == ground_truth_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            ax.axvline(Time[t], c=colors[i], linestyle='--')\n",
    "        continue\n",
    "\n",
    "    if i == chosen_i:\n",
    "        # add a vertical line at each bifurcation point\n",
    "        t_bif = np.where(data_all[i]['time_steps']['is_bifurcation_point'])[0]\n",
    "        print('t_bif:', t_bif)\n",
    "        for t in t_bif:\n",
    "            ax.axvline(Time[t], c=colors[i], linestyle='--')\n",
    "\n",
    "    print(hmax[i])\n",
    "    ax.plot(Time2, err, c=colors[i], label=f'{float(hmax[i]):.2}', linestyle='--', marker='o')\n",
    "    if i == chosen_i:\n",
    "        # plot different style line\n",
    "        ax.plot(Time2, err, c='black', linewidth=4, zorder=-1, )\n",
    "\n",
    "# horizontal line at y=0.05\n",
    "ax.axhline(0.05, c='black', linestyle='--')\n",
    "ax.axhline(0.1, c='black', linestyle=':')\n",
    "\n",
    "# ax.ylim([0, 0.25])\n",
    "ax.set_xlabel(r'$\\tau$')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(r'$\\epsilon_{D}$')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='center right', title=r'$cl_{\\textrm{max}}$',\n",
    "          bbox_to_anchor=(1.45, 0.5))\n",
    "\n",
    "plt.subplots_adjust(left=0.2, right=0.7, bottom=0.2, top=0.9)\n",
    "fig.savefig(f'{geom_base}_mesh_convergence_D.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mesh, before and after deformation\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "p = data_all[ground_truth_i]['mesh']['RVE']['p'] # initial node positions\n",
    "t = data_all[ground_truth_i]['mesh']['RVE']['t'] # initial node positions\n",
    "e = data_all[ground_truth_i]['mesh']['RVE']['edges'] # mesh edges\n",
    "hb_inds = data_all[ground_truth_i]['mesh']['RVE']['hole_boundary_edges_inds'] # indices of the hole boundary edges\n",
    "\n",
    "lv = data_all[ground_truth_i]['geometry']['unit_cell']['lattice_vectors']\n",
    "\n",
    "# deformed position at the last time step of the trajectory\n",
    "p_def = data_all[ground_truth_i]['time_steps']['x'][-1]\n",
    "F_temp = data_all[ground_truth_i]['time_steps']['F'][-1]\n",
    "lv_def = np.dot(F_temp, lv.T).T\n",
    "\n",
    "# plot elements of the original mesh, 2x2 RVE\n",
    "for shifts in [[0, 0], [1, 0], [0, 1], [1, 1]]:\n",
    "    p2 = p +2*shifts[0]*lv[0] +2*shifts[1]*lv[1]\n",
    "\n",
    "    # plot hole boundary edges of deformed mesh\n",
    "    x, y = np.transpose(p2[e[hb_inds].T], axes=[2,0,1])\n",
    "    c='lightgrey'\n",
    "    edges0 = ax.plot(x, y, c=c, linewidth=1)\n",
    "\n",
    "# plot elements and hole boundaries of the deformed mesh, 2x2 RVE\n",
    "for shifts in [[0, 0], [1, 0], [0, 1], [1, 1]]:\n",
    "    p_def2 = p_def +2*shifts[0]*lv_def[0] +2*shifts[1]*lv_def[1]\n",
    "\n",
    "    c = 'darkblue'\n",
    "    x, y = np.transpose(p_def2[e[hb_inds].T], axes=[2,0,1])\n",
    "    edges0 = ax.plot(x, y, c=c, linewidth=1)\n",
    "\n",
    "# set aspect ratio to be equal\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# ax.gca().set_title(f'F={F_final}')\n",
    "temp_str = r'$\\textbf{\\textrm{F}}=\\begin{pmatrix}' + f'{F_temp[0,0]:.2}' + ' & ' + f'{F_temp[0,1]:.2}' + r'\\\\' + f'{F_temp[1,0]:.2}' + ' & ' + f'{F_temp[1,1]:.2}' + r'\\end{pmatrix}$'\n",
    "if data_all[ground_truth_i]['simulations']['error_flag'][-1]:\n",
    "    temp_str = temp_str + r', error_flag!'\n",
    "    # make latex textcolor red\n",
    "    temp_str = r'\\textcolor{red}{' + temp_str + '}'\n",
    "\n",
    "ax.set_title(temp_str)\n",
    "\n",
    "# fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "fig.savefig(f'{geom_base}_mesh_convergence_geometry.pdf', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
